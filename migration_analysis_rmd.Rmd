---
title: "Immigration related debates in UK HOC"
author: "Amir, Ofer, Jan"
date: "12/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction/ problem setting

Frame: we are thinkTank approached by policy makers from the immigration office with the task of informing how immigration was discussed in the HoC. 
- covid, uk entering hardship, immigration will become a sensitive topic, they want to be prepared. 
- they want to get what the uk relation to immigration is, in terms of intensity of discussions and in terms of sentiment
- they have quantities data, but wish to understand better the discourse. 
for that, we came with the following guiding hypothesis:
1. 
2. 
3. 


It’s 1978. Margaret Thatcher takes an interview in the notorious British programme World in Action in which she voices, what in her view, is the recent sentiment of The People regarding immigration. Remarkedly, she notes that “People are really rather afraid that this country might be rather swamped by people with a different culture.” Jumping in time. It’s 2010, David Cameroon wins BY A LOT the general election but nevertheless could not form a coalition, resulting eventually in broad coalition government. It’s 2015 now, an exceptional amount of asylum seekers make their way to European Union (EU), and the United Kingdom (UK) is facing many applications for asylum, double the amount it did just one year before (Riihimäki, 2016). A year ahead, the date is June 23, 2016 and the British decide to withdraw from the EU and make the UK GREAT AGAIN. All in all, things haven’t been easy for the UK.  

Knowing that in part these described transformations were driven by discussions about “people with a different culture” elicits the need to understand how these people are discussed and framed, and whether these frames and sentiments change around specific events such as Brexit and the Migration wave of 2015. A good place to start answering this inquiry is by looking at the parliamentary speeches from the HoC debates because they are held by public elected members who, in principle, represent the interests and voice of their electors.Further, as the discussions in the House are instrumental to the unfolding policies and pieces of legislation regarding immigrants, understanding the views and frames voiced in the discussion may shed light on how these frames impacted resulting policy about immigration. In this sense, our text analysis could result in understanding better a treatment, which allows for induction of future research hypothesis.   

- method and data
- findings

## 2. Packages and data

explain which data has been used and forms the basis of our analysis
-- text analysis, what it is, text sentiment and topic and what can we get out of it.

To understand how immigrants are framed and perceived when discussed in parliamentary debates, we used a database called ParlSpeech V2 by Christian Rauh and Jan Schwalbach (2020). This database is unique in its scope, covering all parliamentary debates from 1998 and up until 2020, resulting in 1,956,223 speeches (Rauh & Schwalbach, 2020, p. 10). The text was collected from the digital Commons Hansard that contains the plenary protocols and documents from which speech texts and metadata are extracted. The corpus contains a range of covariates like party affiliation and agenda which facilitate better analysis of the various ways in which the topic of consideration is discussed by the different parties' representatives and depending on the agenda context. For that end, we also leverage the (established to produce reliable estimates) Lexicoder 2015 sentiment dictionary that consists of 2,858-word patterns relating to negative sentiment and 1,709-word patterns, indicating positive sentiment (Young & Soroka, 2012). 

```{r library}
#load packages
library(quanteda)
library(quanteda.textmodels)
library(quanteda.sentiment)
library(quanteda.textstats)
library(readtext)
library(tidyverse)
library(stm)
library(lubridate)
library(lme4)
library(lattice)
library(wordcloud)
library(ggridges)
library(plotly)
library(tm)
library(dygraphs)
library(xts)
library(ggiraphExtra)
library(car)
#load data
Corp_HouseOfCommons_V2  <- readRDS("~/Desktop/tada-hoc/Corp_HouseOfCommons_V2.rds")
```

### 2.1 Subset

explain the subset + limitations
Choosing a unit for analysis is a challenging task, and in our case, the desicions we took were related both to substentive and practical consideration of needing to narrow down a very large database to perform a more in depth analysis. Thus, we choose to focus on texts from 2010 to present day. 2010 is a good starting point for our analysis because that was the year of the Tory manifesto and the general elections which resulted with a win for the Conservative party. This allow us for a sufficient time frame that has observations both before our main events of interest, namely the 2015 General Election, the migration wave and the Brexit Referendum, and after, from 2016 until 2020.
In terms of content, we subset the corpus only to those speeches that contain a reference to key words related to the topic. Specifically, "immigra", "refugee" or "asylum" because we expect parliamentary debates to be explicit in their language, meaning that if immigration is discussed one of these key words will show either in the agenda description or in the speech itself and therefore we think this method would allow us to capture most of the substantive debates regarding immigration (Van Dijk, 2000). This type of subsetting allows us to focus our analysis and remove noise from unrelated text, and yet, contain the limitation of not including any documents who discuss immigration without mentioning the three key terms chosen in either agenda description or text. Further, by this subsetting we are very likely to loose short responses to speeches carried out. 

```{r subset}

# select time frame 

HoC_corp_time_0 <- Corp_HouseOfCommons_V2 %>% 
  select(!c(iso3country, party.facts.id, parliament)) %>%
  filter(date>"2009-12-20")

# select relevant parties?? # 12/12/2020 note to ourselves: Do we want to subset parties? at least exclude the NAs?


# select relevant content 

HoC_corp_time <- HoC_corp_time_0[HoC_corp_time_0$terms>10,]

key_words_img <- c("immigra*","Immigra*","refugee*","Refugee*","asylum","Asylum"," migra*"," Migra*")
HoC_data <- filter(HoC_corp_time, 
                   grepl(paste(key_words_img,collapse="|"), agenda) | 
                     grepl(paste(key_words_img,collapse="|"), text))

```

### 2.2 Foundational Dateframes & Considerations

mention that we will look at two basic subsets: One general one with all oberservations of the initial subset, and one based on the context of the keywords. Justify why. 

mention events etc. 


*2.2.1 General Corpus*
```{r dataframes, echo=FALSE}

HoC_corp <- corpus(HoC_data)

```

*2.2.2 KWIC - Dataframe, Corpus and Dfm*
```{r dataframes_1, echo=FALSE}

# kwic dataframe, corpus and dfm

HoC_kwic <- kwic(HoC_corp, 
                 paste(key_words_img,collapse="|"), 
                 window = 20)

HoC_kwic_data <- tibble(speaker = HoC_kwic$docname, 
                  text = paste(HoC_kwic$pre, 
                               HoC_kwic$post, sep = " ")) 

HoC_kwic_corp <- corpus(HoC_kwic_data)

HoC_kwic_dfm <- dfm(HoC_kwic_corp, 
                remove_punct = TRUE,
                remove = stopwords(),
                remove_symbols = TRUE,
                remove_separators = TRUE,
                split_hyphens = TRUE,
                remove_numbers = TRUE)
```

*2.2.3 General consideration/definitions used across analysis*
```{r dataframes_3, echo=FALSE}

events <- data.frame(Ref = c("2015 General Election", "Brexit Referendum"),
                     vals = c("2015-05-07", "2016-06-23"),
                     stringsAsFactors = FALSE)

# could also specify e.g. colors (could also not do it ;) :D ) 

```



## 3. Descriptives

Justifications and throughts here.

- Subset covers 3.05% of total debates in that time period and 6.35% of the total time spend in debates.

- This section looks at the overall prevalence of immigration-realted debates in the HoC between 2010 and 2020, irrespective of party.
- We use a density plot that depicts frequency (y) across time. 
- Any reference is based on the subset and therefore immigration-related.
- Plot 1 shows the number of individual contributions made over time. Technically speaking, this equals the total count of documents for each month between 2010 and 2020. Substantively, one document reflect one individual's contribution irrespective of its length, tone etc.
- Findings plot 1: Need to mention spikes and breaks (likely due to the different phases of the HoC; e.g. summer breaks)

- Plot 2 depicts the amount of unique agenda points either dedicated towards or somehow relating to immigration. Substantively, this means that each agenda point, irrespective of its lengths, will be counted.  
- Findings plot 2: The overall amount of agenda points devoted or somehow related to immigration has almost tripled between 2010 and 2020, with a nearly linear increase over the years. , 

- Plot 3. While plot 1 shows the overall count of unique contributions to immigration-related debates, it does not give substantive insights into the lengths of those contributions. We argue that looking at the overall amount of words used within debates is a relatively clear indicator of the time spent on the respective debate. This is important, as the HoC only has a limited time available, devoting more time towards a debate may indicate certain priorities. In this regard, plot 3 depicts the 6-month-average total amount of words spend on immigration-related debates. By looking at the 6-month averages, we are able to observe whether debate-preferances prevailed over time or whether they only peaked over a short time. To give you an example, looking at the number of words on Dec 2011 indicates the monthly-average amount of words spend on immigration related debates during the second half of 2011. 

- Findings plot 3: While sharp ups and downs were still visible in plots 1 and 2, averaging over 6 months allows for a smoother observation of debate evolution. From January 2012 to November 2014 we are able to observe a steady increase in time spend on debates with regards to their 6-month averages. This is likely due to the spikes showing on a monthly level in both January and June of 2014. The second half of 2014 as well as the first half of 2015 saw less time being devoted to immigration related debates. This suggest that overall, the content on which we selected our subset did not increase in particular prevalence before the 2015 General Election. However, Between May 2015 and June 2016, hence the year following the general election and leading up to the Brexit referendum, saw a major increase in time spend on immigration-related debates. On average, the HoC spend almost twice as much time on immigration related debates during Sep 2015 - Feb 2016 when compared to the period of Dec 2014 - May 2015. Hence, debates seem to have gained in priority after the GEneral election and leading up to the referendum. 

```{r subset of all debate, echo=FALSE}

# subset as % of overall debates within same time frame 3.05%

nrow(HoC_data)/nrow(HoC_corp_time_0)*100

# subset as % of time spend 6.35%

sum(HoC_data$terms)/sum(HoC_corp_time_0$terms)*100


# % contribution within subset by party

party_contr <- HoC_data %>%
  group_by(party) %>% 
  summarise(contribution=(sum(terms)/sum(HoC_data$terms))*100)

party_contr[order(party_contr$contribution, decreasing = TRUE),]

# time sepnd on immigration related debates during the year before Election compared to the year before Brexit


contr_elect <- sum(HoC_data$terms[HoC_data$date <= "2015-05-07" & HoC_data$date >= "2014-05-07"])

contr_brex <- sum(HoC_data$terms[HoC_data$date <= "2016-06-23" & HoC_data$date >= "2015-06-23"])

contr_brex/contr_elect # 76.3% more time spend on immigration related debates in year leading up to Brexit compared to the one leading up to election.

```



*Plot 1:* Prevalence of immigration debates over time by month | Counting documents

```{r plot 1, echo=FALSE}

HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

doc_sum_by_month = HoC_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(frequency = n()) 

descr_plot_1 <- xts(x = doc_sum_by_month$frequency, order.by = doc_sum_by_month$month)
names(descr_plot_1) <- "# unique contributions"

dygraph(descr_plot_1, 
             main = "Prevalence of immigration debates (by number of unique contributions)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")

```

*Plot 2:* Prevalence of immigration debates over time by month | Counting unique agenda points

```{r plot 2, echo=FALSE}
# plot: prevalence of immigration debates over time by month | counting unique agenda points
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

sum_by_agenda = HoC_data %>% 
  group_by(month=floor_date(date, "month"), agenda = agenda) %>% 
  summarise(frequency = n()) 

doc_sum_by_agenda = sum_by_agenda %>% 
  group_by(month=floor_date(month, "month")) %>% 
  summarise(frequency = n()) 

descr_plot_2 <- xts(x = doc_sum_by_agenda$frequency, order.by = doc_sum_by_agenda$month)
names(descr_plot_2) <- "# unique debates"

dygraph(descr_plot_2, 
             main = "Prevalence of immigration debates (by number of unique debates)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")
```

*Plot 3:* Prevalence of immigration debates over time by month | Total number of words as a proxy for time spent on debating. 

```{r plot 3, echo=FALSE}
# plot: prevalence of immigration debates over time by month | total number of words as a proxy for time spent on debating. 
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

doc_sum_by_words = HoC_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(word_sum = sum(terms)) 

descr_plot_3 <- xts(x = doc_sum_by_words$word_sum, order.by = doc_sum_by_words$month)
names(descr_plot_3) <- "# words"

# Plot
dygraph(descr_plot_3, 
             main = "Prevalence of immigration debates (as 6-month-averages)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyRoller(rollPeriod = 6)%>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")
```

```{r plot 4: prevalence by party, echo=FALSE}

# library
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

sum_by_party = HoC_data %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(frequency = sum(terms)) 

# Plot
ggplot(sum_by_party, aes(x = month, y = party, fill = party)) +
  geom_density_ridges(alpha=0.6) +
  labs(title = "Number of words spent on immigration-realted debates",
       subtitle = "by party")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red") # Brexit referendum


```

## 4. Keywords in Context

Justification and Thoughts here.
To understand better how key words are discussed in the text we first generated a key words in context data frame which constraints the corpus to only words that appear 10 words before a key word and 10 words after. 

*KWIC - Wordcloud incl. keywords*
```{r kwic, echo=FALSE}
textplot_wordcloud(HoC_kwic_dfm, max_words = 90, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
```

*KWIC - Wordcloud excl. keywords*
```{r kwic_2, echo=FALSE}

## removing also key words to see what is left
HoC_kwic_dfm_no_key <- dfm(HoC_kwic_corp,
                       remove_punct = TRUE,
                       remove = c(as.vector(key_words_img),stopwords()),
                       remove_symbols = TRUE,
                       remove_separators = TRUE,
                       split_hyphens = TRUE,
                       remove_numbers = TRUE)

textplot_wordcloud(HoC_kwic_dfm_no_key, max_words = 90, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
```

*Plot* Top words co-concurence matrix of key words in context

```{r}
#plot feature concourence matrix
HoC_kwic_fcm <-
  tokens(HoC_kwic_corp, remove_punct = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("english"), padding = FALSE) %>%
  fcm(context = "window", window = 5, tri = FALSE)
# choose 30 most frequency features
topfeats <- names(topfeatures(HoC_kwic_fcm, 30))
# select the top 30 features only, plot the network
set.seed(100)
textplot_network(fcm_select(HoC_kwic_fcm, topfeats), min_freq = 0.8)
```

*Frequency of words related to migration (including key terms)*
```{r kwic_3, echo=FALSE}

HoC_dfm_word_freq <- textstat_frequency(HoC_dfm, n=100)
# Sort by reverse frequency order
HoC_dfm_word_freq$feature <- with(HoC_dfm_word_freq, reorder(feature, -frequency))

ggplot(HoC_dfm_word_freq, 
       aes(x = feature, y = frequency)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```




## 5. Sentiment


*Sentiment | Overall Corpus*
```{r sentiment, echo=FALSE}
sentiment <- textstat_polarity(HoC_corp, 
                               data_dictionary_LSD2015)

sentiment$sent_prob <- 1/(1 + exp(-sentiment$sentiment))

# add sentiment to initial data frame
HoC_data = cbind(HoC_data,sentiment) 
```

*Graph 1: Overall Sentiment*
```{r sentiment graph 1, echo=FALSE}

HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")
HoC_senti_data <- data.frame(date = HoC_data$date, 
                           sentiment = HoC_data$sentiment)

HoC_senti_data_month = HoC_senti_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(avg_sentiment = mean(sentiment))


ggplot(HoC_senti_data_month, aes(x=month, y=avg_sentiment))+
  geom_area( fill="#69b3a2", alpha=0.4, aes(group=1)) +
  geom_line(color="#69b3a2",aes(group=1)) +
  labs(title = "Observed Sentiment in immigration related contributions overall",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))
```

*Graph 2: Sentiment by party*
```{r sentiment graph 2, echo=FALSE}

HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

HoC_senti_data_party <- data.frame(
  date = HoC_data$date, 
  party = HoC_data$party,
  sentiment = HoC_data$sentiment)

HoC_senti_data_party <- HoC_senti_data_party %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

party_senti_plot <- ggplot(HoC_senti_data_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in immigration related contributions overall by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

# turn into interactive graph
party_senti_plot <- ggplotly(party_senti_plot)
party_senti_plot

```

*Sentiment | Keywords in Context*
```{r sentiment kwic, echo=FALSE}

kwic_sentiment <- textstat_polarity(HoC_kwic_corp, 
                                    data_dictionary_LSD2015)

kwic_sentiment$sent_prob <- 1/(1 + exp(-kwic_sentiment$sentiment))

# add sentiments to initial data frame
HoC_kwic <- cbind(HoC_kwic, kwic_sentiment) 

## KWIC sentiment

length(unique(HoC_data$doc_id)) # for merge, check if doc_id is unique --> yes. 
doc_id_date <- data.frame(date = HoC_data$date,
                          docname = HoC_data$doc_id, 
                          party = HoC_data$party) # add date column to kwic

kwic_date <- merge(HoC_kwic, 
                     doc_id_date, 
                     by = "docname", 
                     all.x = TRUE, 
                     sort = FALSE) # will need to merge based on the docname, as this is the same as the initial doc_id.
```

*Graph 3: KWIC sentiment*
```{r sentiment kwic graph 3, echo=FALSE}

kwic_date$date <- as.Date(kwic_date$date, format="%Y-%m-%d")

HoC_kwic_senti_data <- data.frame(
  date = kwic_date$date, 
  sentiment = kwic_date$sentiment)

HoC_kwic_senti_month = HoC_kwic_senti_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(avg_sentiment = mean(sentiment))

ggplot(HoC_kwic_senti_month, aes(x=month, y=avg_sentiment)) +
  geom_area( fill="#69b3a2", alpha=0.4, aes(group=1)) +
  geom_line(color="#69b3a2",aes(group=1)) +
  labs(title = "Observed Sentiment in Context of Keywords in immigration related contributions",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum") +
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red") + # Brexit referendum
  theme(axis.text.x = element_text(angle = 90))
```

*Graph 4: KWIC sentiment by party*
```{r sentiment kwic graph 4, echo=FALSE}

kwic_date$date <- as.Date(kwic_date$date, format="%Y-%m-%d")

HoC_kwic_senti_data_party <- data.frame(
  date = kwic_date$date, 
  party = kwic_date$party,
  sentiment = kwic_date$sentiment)

HoC_kwic_senti_party = HoC_kwic_senti_data_party %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

kwic_senti_party_plot <- ggplot(HoC_kwic_senti_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_kwic_senti_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_kwic_senti_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in in context of keyword immigration related contributions by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

# turn into interactive graph
kwic_senti_party_plot <- ggplotly(kwic_senti_party_plot)
kwic_senti_party_plot

```


## 6. Topics

Text here

*Create Dfm* Include here to also include sentiment in the dfm.
```{r topics_dfm, echo=FALSE}

HoC_dfm <- dfm(HoC_corp, 
                  remove_punct = TRUE,
                  remove = stopwords(),
                  remove_symbols = TRUE,
                  remove_separators = TRUE,
                  split_hyphens = TRUE,
                  remove_numbers = TRUE)

HoC_dfm <- dfm_trim(HoC_dfm,
                  min_termfreq = 2, 
                  min_docfreq = 2)
HoC_dfm <- dfm_subset(HoC_dfm, rowSums(HoC_dfm)>0)

HoC_stm <-asSTMCorpus(HoC_dfm)
```


```{r topics, echo=FALSE}
########################
# Running topic model 1#
########################
# fit a simple model with 6 topics
topic_mod_1 <- stm(HoC_dfm, K = 6, seed = 12345)
topic_labels <- labelTopics(topic_mod_1)
plot(topic_mod_1, type = "labels", labeltype = "prob") # or frex, lift, score

# extract paragraphs most aligned with each topic
thoughts <- findThoughts(topic_mod_1, texts = texts(HoC_corp), n=1, topics = c(1:6))#n=how many documents
#plot thoughts for topics
stm::plotQuote(thoughts$docs$`Topic 4`, width = 80, text.cex=0.6)
save(thoughts, file = "thoughts.RData")

# wordcloud
cloud(topic_mod_1, topic = 6, max_words = 90, color = c(color = rev(RColorBrewer::brewer.pal(10, "RdBu"))))

# check if topics are exclusive
dotchart(exclusivity(topic_mod_1), labels = 1:6, color = 1:6)

# check if topics are coherent
cohere <- semanticCoherence(topic_mod_1, HoC_dfm)
dotchart(cohere, labels = 1:6, color = 1:6)

#topic model key words in context
topic_mod_2 <- stm(HoC_kwic_dfm, K = 6, seed = 12345)
topic_labels_2 <- labelTopics(topic_mod_2)
plot(topic_mod_2, type = "labels", labeltype = "prob") 
# extract paragraphs most aligned with each topic
thoughts_2 <- findThoughts(topic_mod_2, texts = texts(HoC_kwic_corp), n=1, topics = c(1:6)) #n=how many documents
save(thoughts_2, file = "thoughts_2.RData")
#plot thoughts for topics
stm::plotQuote(thoughts_2$docs, width = 80, text.cex=0.6)
```


```{r topics dataframe, echo=FALSE}
###################################
# Creating topic model data frame #
###################################

# combine stm thetas with dfm docvars
HoC_theta_data <- as.data.frame(topic_mod_1$theta) %>%
  cbind(docvars(HoC_dfm))

## naming topics
#combine first 3 labels as a string for a new label
labels_topic_mod_1 <- c()
for (topicnumber in topic_labels$topicnums){
  first_3<-(str_c(topic_labels$frex[topicnumber,1], 
                  ", " , topic_labels$frex[topicnumber,2], 
                  ", " , topic_labels$frex[topicnumber,3]))
  labels_topic_mod_1<- append(labels_topic_mod_1, first_3)
}

# renaming columns
names(HoC_theta_data)[1:6] <- labels_topic_mod_1


###

####################################
# save/load topic model data frame #
####################################

# save and load topic model dataframe
save(HoC_theta_data, file = "HoC_theta_data.RData")
load("HoC_theta_data.RData")
```


Topic Visualizations:

```{r topic_by_party_plot, echo=FALSE}

## topic_by_party_plot: topic proportions by party 

# grouping by party and generating means 
theta_data_party <- HoC_theta_data %>%
  filter(party == "Con" | party == "Lab" |  party == "LibDem" | party == "SNP" | party == "DUP") %>%
  group_by(party)

theta_data_party_mean <- aggregate(theta_data_party[, 1:6], 
                                   list(theta_data_party$party), 
                                   mean)
names(theta_data_party_mean)[1] <- "Party" 

# Turning into a table of proportions
theta_data_party_prop <- theta_data_party_mean[1] %>%
  cbind(as.data.frame(
    round(100*prop.table(theta_data_party_mean[2:7]),
          digits=2)))

# pivoting df for making figure
party_prop_long <-theta_data_party_prop %>%
  pivot_longer(c(2:7), 
               names_to = "Topic", 
               values_to = "Proportion")

# visualizing proportions of topics by party
topic_by_party_plot <- party_prop_long %>%
  ggplot(aes(Party, Proportion, fill = Topic)) +
  geom_bar(position = "fill", stat = "identity") +
  scale_y_continuous() + 
  theme(axis.text.x = element_text(angle = 45, 
                                   hjust = 1, 
                                   size = 6))
topic_by_party_plot
```


```{r topics_by_time_plot, echo=FALSE}

## topic_by_party_plot: topic proportions by party 

theta_data_long <- pivot_longer(
  HoC_theta_data, 
  cols = names(HoC_theta_data[1:6]), 
  names_to = "topic",
  values_to = "theta")

# plot topic theta means over years
theta_long_data_year <- theta_data_long %>%
  mutate(year = str_sub(date, 1, 4)) %>%
  group_by(year, topic) %>% 
  dplyr::summarise(theta.means = mean(theta))


ggplot(theta_long_data_year,aes(x=year, y=theta.means, group = 1, color = topic)) + 
  geom_point() +
  geom_line() +
  geom_vline(xintercept = "2015", linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = "2016", linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~topic)
```

```{r ind_topics_by_time_by_party_plot, echo=FALSE}

####### showing development of 1 topic over time across parties
# plot topic theta means by party over years
theta_long_data_year_1 <- theta_data_long %>%
  mutate(year = str_sub(date, 1, 4)) %>%
  group_by(year, topic, party) %>% 
  dplyr::summarise(theta.means = mean(theta)) %>%
  filter(party == "Con" | party == "Lab" |  party == "LibDem" | party == "SNP" | party == "DUP")

# plot all parties together (plot by topic, color by party)
k <- ggplot()  +
  geom_line(data = theta_long_data_year_1, aes(x=year, y = theta.means, group = party, colour = party)) + 
  geom_line(data = theta_long_data_year,aes(x=year, y=theta.means, group = 1)) +
  geom_vline(xintercept = "2015", linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = "2016", linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~topic)

# make interactive
k <- ggplotly(k)

k
```

```{r topics_4 Amir: I don't think we need these anymore, echo=FALSE}

# graph sentiment by topics
sentiment_data_long <- theta_data_long %>%
  mutate(year = str_sub(date, 1, 4)) %>%
  group_by(year, topic, party) %>% 
  summarise(sentiment.means = mean(sentiment)) %>%
  filter(party == "Con" | party == "Lab" | party == "GPEW" | party == "Independent" | party == "LibDem" | party == "PlaidCymru" | party == "SDLP" | party == "SNP")

sentiment_long_party <- cbind(sentiment_data_long, theta.means = theta_long_data_year_1$theta.means)

sentiment_long_party$year <- as.Date(sentiment_long_party$year, format = "%Y")

ggplot(sentiment_long_party)+
  geom_line(aes(x = year, y=sentiment.means, group=party), colour = "grey") +
  geom_line(data = subset(sentiment_long_party, party == "Con"), aes(x = year, y=sentiment.means, group=party), colour = "blue") +
  geom_line(data = subset(sentiment_long_party, party == "Lab"), aes(x = year, y=sentiment.means, group=party), colour = "red") +
  labs(title = "Observed Sentiment by partyand topic",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~topic)


# Topic prevalence and observed Sentiment by party for Conservatives and Labour. 
ggplot(subset(sentiment_long_party, party == c("Con","Lab")))+
  geom_line(aes(x = year, y=theta.means, color = topic)) +
  geom_line(data = subset(sentiment_long_party, party == c("Con","Lab")), aes(x = year, y=sentiment.means), linetype="dashed", colour = "darkgrey") +
  labs(title = "Topic prevalence and observed Sentiment by party",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~party)



# Topic prevalence and observed Sentiment by party for Conservatives and Labour. 
ggplot(subset(sentiment_long_party, party == c("Con","Lab", "GPEW", "Independent", "LibDem", "PlaidCymru", "SDLP", "SNP")))+
  geom_line(aes(x = year, y=theta.means, color = topic)) +
  geom_line(data = subset(sentiment_long_party, party == c("Con","Lab", "GPEW", "Independent", "LibDem", "PlaidCymru", "SDLP", "SNP")), aes(x = year, y=sentiment.means), linetype="dashed", colour = "darkgrey") +
  labs(title = "Topic prevalence and observed Sentiment by party",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~party)


```

```{r topics-sentiment regression, echo=FALSE}
# filter sentiment data frame

theta_data_long_reg <- theta_data_long %>%
  filter(party == "Con" | party == "Lab" |  party == "LibDem" | party == "SNP" | party == "DUP")


#subset data to just one topic (1)
sentiment_topic1 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[1])

#subset data to just one topic (2)
sentiment_topic2 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[2])

#subset data to just one topic (3)
sentiment_topic3 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[3])

#subset data to just one topic (4)
sentiment_topic4 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[4])

#subset data to just one topic (5)
sentiment_topic5 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[5])

#subset data to just one topic (6)
sentiment_topic6 <- theta_data_long_reg %>%
  filter(topic == names(HoC_theta_data)[6])

#### regression models for each topic (effect of topic on sentiment, controlling for party and year)

# disagregated by topic

# names(HoC_theta_data)[1]
reg1 <- lm(sentiment~theta+party+date, data=sentiment_topic1)

# names(HoC_theta_data)[2]
reg2 <- lm(sentiment~theta+party+date, data=sentiment_topic2)

# names(HoC_theta_data)[3]
reg3 <- lm(sentiment~theta+party+date, data=sentiment_topic3)

# names(HoC_theta_data)[4]
reg4 <- lm(sentiment~theta+party+date, data=sentiment_topic4)

# names(HoC_theta_data)[5]
reg5 <- lm(sentiment~theta+party+date, data=sentiment_topic5)

# names(HoC_theta_data)[6]
reg6 <- lm(sentiment~theta+party+date, data=sentiment_topic6)

library(stargazer)
#stargazer(reg1, reg2, reg3, reg4, reg5, reg6, column.labels = c(names(HoC_theta_data)[1:6]), type = "text")
stargazer(reg1, reg2, reg3, reg4, reg5, reg6, type = "text")
```

```{r topics-sentiment regression plot, echo=FALSE}
# for all parties (no color)
ggplot(theta_data_long_reg,aes(y=sentiment,x=theta)) +
  #geom_point(alpha = 0.05, shape = ".") +
  geom_smooth(method="lm", show.legend = FALSE) +
  theme_bw() + 
  xlab("Topic Theta") +
  ylab("Sentiment") +
  ggtitle("Correlation Between Sentiment and Topic") +
  facet_wrap(~topic)
```

```{r topics-sentiment regression plot by party, echo=FALSE}
# for all parties (color)
ggplot(theta_data_long_reg,aes(y=sentiment,x=theta, color = party, fill = party)) +
  #geom_point(alpha = 0.05, shape = ".") +
  geom_smooth(method="lm") +
  theme_bw() + 
  xlab("Topic Theta") +
  ylab("Sentiment") +
  ggtitle("Correlation Between Sentiment and Topic") +
  facet_wrap(~topic)
```


## 7. Exploratory part (just for ourselves)
Leave out in the end!


```{r topics_5, echo=FALSE}
# fit a simple model with 12 topics
topic_mod_2 <- stm(HoC_dfm, K = 12, seed = 12345)
labelTopics(topic_mod_2)
#plot(topic_mod_2, type = "labels", labeltype = "prob") # or frex, lift, score
findThoughts
# check if topics are exclusive 
dotchart(exclusivity(topic_mod_2), labels = 1:12)

#check if topics are coherent
cohere <- semanticCoherence(topic_mod_2, HoC_dfm)
dotchart(cohere, labels = 1:12)

```


```{r topics_6, echo=FALSE}
# topic model prevelance by party
# new topic model mod3  --> @Amir check why error showss up regarding content covariate lenght? 

topic_mod_3 <- stm(HoC_stm$documents, vocab = HoC_stm$vocab, 
             K = 6, ~ party, data=HoC_stm$data, seed = 12345)
#estimating the effect in term of topic-proportions which are the outcome variable. 
#conditional expectation of topic prevalence given document characteristics.
topic_mod_3 <- estimateEffect(1:6~HoC_stm$party, topic_mod_1, HoC_stm)

#plot to see exclusivity of topics
plot(topicCorr(topic_mod_3))
#plot to chec
topicQuality(topic_mod_3, documents = HoC_stm$documents)
dim(topic_mod_3$beta$logbeta[[1]])

#code to add labels
labels <- apply(sageLabels(topic_mod_1)$marginal$frex, 1,
                function(x){ paste(x[1:4], collapse = "-") })


```

```{r just for us, echo=FALSE}

# some examples of agendas
head(unique(Corp_HouseOfCommons_V2$agenda))
#number of agendas
length(unique(Corp_HouseOfCommons_V2$agenda))
length(Corp_HouseOfCommons_V2$agenda)
Corp_HouseOfCommons_V2$agenda["migration"]

## just to check what the sentiment analysis does: 

text <- data.frame(text =c("nice","evil","and"))
text <- corpus(text)
sent_text <- textstat_polarity(text, 
                               data_dictionary_LSD2015)


#### Sentiment only for refugee* by party
refu <- c("refugee*","Refugee*")
refugee <- filter(HoC_corp_time, grepl(paste(refu,collapse="|"), agenda) | grepl(paste(refu,collapse="|"), text))
refcorp <- corpus(refugee)

ref_sent <- textstat_polarity(refcorp, 
                              data_dictionary_LSD2015)
ref_sent$sent_prob <- 1/(1 + exp(-ref_sent$sentiment))

refugee = cbind(refugee,ref_sent)

refugee$date <- as.Date(refugee$date, format="%Y-%m-%d")
ref_party_df <- data.frame(date = refugee$date, party = refugee$party ,sentiment = refugee$sentiment)
ref_party = ref_party_df %>% group_by(month=floor_date(date, "month"), party = party) %>% summarise(avg_sentiment = mean(sentiment))

ggplot(ref_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(ref_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  geom_line(data = subset(ref_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  labs(title = "Observed Sentiment in refugee*- related contributions overall by party",
       subtitle = "Conservative = red, Labour = blue",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red")+ # Brexit referendum
  theme(axis.text.x = element_text(angle = 90))


```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
