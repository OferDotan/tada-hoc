---
title: "Immigration related debates in UK HOC"
author: "Amir, Ofer, Jan"
date: "12/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## 1. Introduction/ problem setting

Frame: we are thinkTank approached by policy makers from the immigration office with the task of informing how immigration was discussed in the HoC. 
- covid, uk entering hardship, immigration will become a sensitive topic, they want to be prepared. 
- they want to get what the uk relation to immigration is, in terms of intensity of discussions and in terms of sentiment
-understanding topics and sentiment is important for coalition building 
- they have quantities data, but wish to understand better the discourse. 
for that, we came with the following guiding hypothesis:
1. 
2. 
3. 


It’s 1978. Margaret Thatcher takes an interview in the notorious British programme World in Action in which she voices, what in her view, is the recent sentiment of The People regarding immigration. Remarkedly, she notes that “People are really rather afraid that this country might be rather swamped by people with a different culture.” Jumping in time. It’s 2010, David Cameroon wins BY A LOT the general election but nevertheless could not form a coalition, resulting eventually in broad coalition government. It’s 2015 now, an exceptional amount of asylum seekers make their way to European Union (EU), and the United Kingdom (UK) is facing many applications for asylum, double the amount it did just one year before (Riihimäki, 2016). A year ahead, the date is June 23, 2016 and the British decide to withdraw from the EU and make the UK GREAT AGAIN. All in all, things haven’t been easy for the UK.  

Knowing that in part these described transformations were driven by discussions about “people with a different culture” elicits the need to understand how these people are discussed and framed, and whether these frames and sentiments change around specific events such as Brexit and the Migration wave of 2015. A good place to start answering this inquiry is by looking at the parliamentary speeches from the HoC debates because they are held by public elected members who, in principle, represent the interests and voice of their electors.Further, as the discussions in the House are instrumental to the unfolding policies and pieces of legislation regarding immigrants, understanding the views and frames voiced in the discussion may shed light on how these frames impacted resulting policy about immigration. In this sense, our text analysis could result in understanding better a treatment, which allows for induction of future research hypothesis.   

- method and data
- findings

## 2. Packages and data

explain which data has been used and forms the basis of our analysis
-- text analysis, what it is, text sentiment and topic and what can we get out of it.

To understand how immigrants are framed and perceived when discussed in parliamentary debates, we used a database called ParlSpeech V2 by Christian Rauh and Jan Schwalbach (2020). This database is unique in its scope, covering all parliamentary debates from 1998 and up until 2020, resulting in 1,956,223 speeches (Rauh & Schwalbach, 2020, p. 10). The text was collected from the digital Commons Hansard that contains the plenary protocols and documents from which speech texts and metadata are extracted. The corpus contains a range of covariates like party affiliation and agenda which facilitate better analysis of the various ways in which the topic of consideration is discussed by the different parties' representatives and depending on the agenda context. For that end, we also leverage the (established to produce reliable estimates) Lexicoder 2015 sentiment dictionary that consists of 2,858-word patterns relating to negative sentiment and 1,709-word patterns, indicating positive sentiment (Young & Soroka, 2012). 

```{r load packages, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
library(quanteda)
library(quanteda.textmodels)
library(quanteda.sentiment)
library(quanteda.textstats)
library(readtext)
library(tidyverse)
library(stm)
library(lubridate)
library(lme4)
library(lattice)
library(wordcloud)
library(ggridges)
library(plotly)
library(tm)
library(dygraphs)
library(xts)
library(ggiraphExtra)
library(car)
```

```{r load data, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

Corp_HouseOfCommons_V2  <- readRDS("~/Desktop/tada-hoc/Corp_HouseOfCommons_V2.rds")
```


### 2.1 Subset

explain the subset + limitations
Choosing a unit for analysis is a challenging task, and in our case, the desicions we took were related both to substantive and practical consideration of needing to narrow down a very large database to perform a more in depth analysis. Thus, we choose to focus on texts from 2010 to present day. 2010 is a good starting point for our analysis because that was the year of the Tory manifesto and the general elections which resulted with a win for the Conservative party. This allow us for a sufficient time frame that has observations both before our main events of interest, namely the 2015 General Election, the migration wave and the Brexit Referendum, and after, from 2016 until 2020.
In terms of content, we subset the corpus only to those speeches that contain a reference to key words related to the topic. Specifically, "immigra", "refugee" or "asylum" because we expect parliamentary debates to be explicit in their language, meaning that if immigration is discussed one of these key words will show either in the agenda description or in the speech itself and therefore we think this method would allow us to capture most of the substantive debates regarding immigration (Van Dijk, 2000). This type of subsetting allows us to focus our analysis and remove noise from unrelated text, and yet, contain the limitation of not including any documents who discuss immigration without mentioning the three key terms chosen in either agenda description or text. Further, by this subsetting we are very likely to loose short responses to speeches carried out. 

```{r subset, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

# select time frame 

HoC_corp_time_0 <- Corp_HouseOfCommons_V2 %>% 
  select(!c(iso3country, party.facts.id, parliament)) %>%
  filter(date>"2009-12-31") #749177 obs.


# select relevant content 

HoC_corp_time <- HoC_corp_time_0[HoC_corp_time_0$terms>10,] #708998 obs.

key_words_img <- c("immigra*","Immigra*","refugee*","Refugee*","asylum","Asylum"," migra*"," Migra*")
HoC_data <- filter(HoC_corp_time, 
                   grepl(paste(key_words_img,collapse="|"), agenda) | 
                     grepl(paste(key_words_img,collapse="|"), text)) #22909 obs.

# select the 5 parties with highest contribution, covering >98% of the initial content

party_contr <- HoC_data %>%
  group_by(party) %>% 
  summarise(contribution=(sum(terms)/sum(HoC_data$terms))*100)

party_contr <- party_contr[order(party_contr$contribution, decreasing = TRUE),]

parties <- party_contr$party[1:5]

HoC_data <- filter(HoC_data, grepl(paste(parties,collapse="|"), party))#22257 obs.


```

### 2.2 Foundational Dateframes & Considerations

mention that we will look at two basic subsets: One general one with all obrservations of the initial subset, and one based on the context of the keywords. Justify why. 

mention events etc. 


*2.2.1 General Corpus*
```{r dataframes, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

HoC_corp <- corpus(HoC_data)

```


*2.2.3 General consideration/definitions used across analysis*
```{r dataframes_3, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

events <- data.frame(Ref = c("2015 General Election", "Brexit Referendum"),
                     vals = c("2015-05-07", "2016-06-23"),
                     stringsAsFactors = FALSE)

```



## 3. Descriptives

Justifications and throughts here.

- Subset covers 3.05% of total debates in that time period and 6.35% of the total time spend in debates.

- This section looks at the overall prevalence of immigration-realted debates in the HoC between 2010 and 2020, irrespective of party.
- We use a density plot that depicts frequency (y) across time. 
- Any reference is based on the subset and therefore immigration-related.
- Plot 1 shows the number of individual contributions made over time. Technically speaking, this equals the total count of documents for each month between 2010 and 2020. Substantively, one document reflect one individual's contribution irrespective of its length, tone etc.
- Findings plot 1: Need to mention spikes and breaks (likely due to the different phases of the HoC; e.g. summer breaks)

- Plot 2 depicts the amount of unique agenda points either dedicated towards or somehow relating to immigration. Substantively, this means that each agenda point, irrespective of its lengths, will be counted.  
- Findings plot 2: The overall amount of agenda points devoted or somehow related to immigration has almost tripled between 2010 and 2020, with a nearly linear increase over the years. , 

- Plot 3. While plot 1 shows the overall count of unique contributions to immigration-related debates, it does not give substantive insights into the lengths of those contributions. We argue that looking at the overall amount of words used within debates is a relatively clear indicator of the time spent on the respective debate. This is important, as the HoC only has a limited time available, devoting more time towards a debate may indicate certain priorities. In this regard, plot 3 depicts the 6-month-average total amount of words spend on immigration-related debates. By looking at the 6-month averages, we are able to observe whether debate-preferances prevailed over time or whether they only peaked over a short time. To give you an example, looking at the number of words on Dec 2011 indicates the monthly-average amount of words spend on immigration related debates during the second half of 2011. 

- Findings plot 3: While sharp ups and downs were still visible in plots 1 and 2, averaging over 6 months allows for a smoother observation of debate evolution. From January 2012 to November 2014 we are able to observe a steady increase in time spend on debates with regards to their 6-month averages. This is likely due to the spikes showing on a monthly level in both January and June of 2014. The second half of 2014 as well as the first half of 2015 saw less time being devoted to immigration related debates. This suggest that overall, the content on which we selected our subset did not increase in particular prevalence before the 2015 General Election. However, Between May 2015 and June 2016, hence the year following the general election and leading up to the Brexit referendum, saw a major increase in time spend on immigration-related debates. On average, the HoC spend almost twice as much time on immigration related debates during Sep 2015 - Feb 2016 when compared to the period of Dec 2014 - May 2015. Hence, debates seem to have gained in priority after the GEneral election and leading up to the referendum. 

```{r subset of all debate, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

# subset as % of overall debates within same time frame 2.97%

nrow(HoC_data)/nrow(HoC_corp_time_0)*100

# subset as % of time spend 6.244%

sum(HoC_data$terms)/sum(HoC_corp_time_0$terms)*100


# time spend on immigration related debates during the year before Election compared to the year before Brexit


contr_elect <- sum(HoC_data$terms[HoC_data$date <= "2015-05-07" & HoC_data$date >= "2014-05-07"])

contr_brex <- sum(HoC_data$terms[HoC_data$date <= "2016-06-23" & HoC_data$date >= "2015-06-23"])

contr_brex/contr_elect # 75.2% more time spend on immigration related debates in year leading up to Brexit compared to the one leading up to election.

```
```{r plot 1, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
# *Plot 1:* Prevalence of immigration debates over time by month | Counting documents
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

doc_sum_by_month = HoC_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(frequency = n()) 

descr_plot_1 <- xts(x = doc_sum_by_month$frequency, order.by = doc_sum_by_month$month)
names(descr_plot_1) <- "# unique contributions"

dygraph(descr_plot_1, 
             main = "Prevalence of immigration debates (by number of unique contributions)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")

```
```{r plot 2, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
#*Plot 2:* Prevalence of immigration debates over time by month | Counting unique agenda points
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

sum_by_agenda = HoC_data %>% 
  group_by(month=floor_date(date, "month"), agenda = agenda) %>% 
  summarise(frequency = n()) 

doc_sum_by_agenda = sum_by_agenda %>% 
  group_by(month=floor_date(month, "month")) %>% 
  summarise(frequency = n()) 

descr_plot_2 <- xts(x = doc_sum_by_agenda$frequency, order.by = doc_sum_by_agenda$month)
names(descr_plot_2) <- "# unique debates"

dygraph(descr_plot_2, 
             main = "Prevalence of immigration debates (by number of unique debates)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")
```

*Plot 3:* Prevalence of immigration debates over time by month | Total number of words as a proxy for time spent on debating. 

```{r plot 3, echo=FALSE,  message = FALSE}
# plot: prevalence of immigration debates over time by month | total number of words as a proxy for time spent on debating. 
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

doc_sum_by_words = HoC_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(word_sum = sum(terms)) 

descr_plot_3 <- xts(x = doc_sum_by_words$word_sum, order.by = doc_sum_by_words$month)
names(descr_plot_3) <- "# words"

# Plot
dygraph(descr_plot_3, 
             main = "Prevalence of immigration debates (as 6-month-averages)", 
             ylab =  "# of words spent on immigration-realted debates", xlab = "Year (by month)") %>% 
  dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.4, drawGrid = FALSE, colors="#69b3a2") %>%
  dyRangeSelector() %>%
  dyCrosshair(direction = "vertical") %>%
  dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
  dyRoller(rollPeriod = 6)%>%
  dyEvent(x="2015-05-07", label = "General Election 2015")%>%
  dyEvent(x="2016-06-23", label = "Brexit Referendum", color = "red")
```
*Concentration of party-specific contributions*

```{r plot 4: prevalence by party, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE }

# library
HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

sum_by_party = HoC_data %>% 
  group_by(month=floor_date(date, "day"), party = party) %>% 
  summarise(frequency = sum(terms)) 

# Plot
ggplot(sum_by_party, aes(x = month, y = party, fill = party)) +
  geom_density_ridges(alpha=0.6) +
  labs(title = "Number of words spent on immigration-realted debates",
       subtitle = "by party")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red") # Brexit referendum

```

This density plot gives us a sense of the frequency each party discussed each party discussed each month during the time frame of our research. Basically what it does it counts how many words each party each party invested in speaking about immigration related topics. So for example, while the SNP and the DUP spoke more about immigration after Brexit, other parties exhibit a more constant trend of engagement with immigration related speech. Importantly, the information that can be gathered from this graph is limited in that it does not tell us anything about substance of these speeches, but crudely how many words were used. Nevertheless, this descriptive visualization does help us get an initial sense about the prevelance of immigration related speech in each of the parties we are focusing on.      

## 4. Sentiment


*Sentiment | Overall Corpus*
```{r sentiment, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
sentiment <- textstat_polarity(HoC_corp, 
                               data_dictionary_LSD2015)

sentiment$sent_prob <- 1/(1 + exp(-sentiment$sentiment))

# add sentiment to initial data frame
HoC_data = cbind(HoC_data,sentiment) 
```

*Graph 1: Overall Sentiment*
```{r sentiment graph 1, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")
HoC_senti_data <- data.frame(date = HoC_data$date, 
                           sentiment = HoC_data$sentiment)

HoC_senti_data_month = HoC_senti_data %>% 
  group_by(month=floor_date(date, "month")) %>% 
  summarise(avg_sentiment = mean(sentiment))


ggplot(HoC_senti_data_month, aes(x=month, y=avg_sentiment))+
  geom_area( fill="#69b3a2", alpha=0.4, aes(group=1)) +
  geom_line(color="#69b3a2",aes(group=1)) +
  labs(title = "Observed Sentiment in immigration related contributions overall",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))
```

*Graph 2: Sentiment by party*
```{r sentiment graph 2, echo=FALSE,  message = FALSE}

HoC_data$date <- as.Date(HoC_data$date, format="%Y-%m-%d")

HoC_senti_data_party <- data.frame(
  date = HoC_data$date, 
  party = HoC_data$party,
  sentiment = HoC_data$sentiment)

HoC_senti_data_party <- HoC_senti_data_party %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

party_senti_plot <- ggplot(HoC_senti_data_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in immigration related contributions overall by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

# turn into interactive graph
party_senti_plot <- ggplotly(party_senti_plot)
party_senti_plot

```



## 5. Sentiment in Context

*2.2.2 Create KWIC - Dataframe, Corpus and Dfm*
```{r dataframes_1, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
#rerun general corpus to include sentiment
HoC_corp <- corpus(HoC_data)

#remove weird strings - only relevant for kwic as we want to analyze sentiment by keywords.

HoC_corp <- gsub("[[:punct:]]â"," ", HoC_corp) # manually retrieved by investigating unique keyword-strings 
HoC_corp <- gsub("([œ])","", HoC_corp)
HoC_corp <- gsub("([â])","", HoC_corp)

HoC_kwic <- kwic(HoC_corp, 
                 paste(key_words_img,collapse="|"), 
                 window = 20,
                 split_hyphens = TRUE)

HoC_kwic_data <- tibble(speaker = HoC_kwic$docname, 
                  text = paste(HoC_kwic$pre, 
                               HoC_kwic$post, sep = " "),
                  keyword = HoC_kwic$keyword,
                  docname = HoC_kwic$docname) 
```


*Subset KWIC according to keywords*
```{r sentiment kwic, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

imm <- c("immigra*","Immigra*")
refu <- c("refugee*","Refugee*")
asyl <- c("asylum","Asylum")

kwic_imm <- filter(HoC_kwic_data,
                   grepl(paste(imm,collapse="|"), keyword))
kwic_refu <- filter(HoC_kwic_data,
                   grepl(paste(refu,collapse="|"), keyword))
kwic_asyl <- filter(HoC_kwic_data,
                   grepl(paste(asyl,collapse="|"), keyword))

```

```{r sentiment kwic 2, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}
# make individual corpora
kwic_imm_corp <- corpus(kwic_imm)
kwic_refu_corp <- corpus(kwic_refu)
kwic_asyl_corp <- corpus(kwic_asyl)

```




*Sentiment  Keywords in Context of keyword*
```{r sentiment kwic 3,results = 'hide', message = FALSE, warning=FALSE, echo=FALSE, fig.show='hide'}

kwic_imm_senti <- textstat_polarity(kwic_imm_corp, 
                                    data_dictionary_LSD2015)
kwic_refu_senti <- textstat_polarity(kwic_refu_corp, 
                                    data_dictionary_LSD2015)
kwic_asyl_senti <- textstat_polarity(kwic_asyl_corp, 
                                    data_dictionary_LSD2015)


# add sentiments to initial data frame

kwic_imm <- cbind(kwic_imm, kwic_imm_senti) 
kwic_refu <- cbind(kwic_refu, kwic_refu_senti)
kwic_asyl <- cbind(kwic_asyl, kwic_asyl_senti)

## add date and party 

doc_id_date <- data.frame(date = HoC_data$date,
                          docname = HoC_data$doc_id, 
                          party = HoC_data$party) # add date column to kwic

kwic_imm_fv <- merge(kwic_imm, 
                     doc_id_date, 
                     by = "docname", 
                     all.x = TRUE, 
                     sort = FALSE)
kwic_refu_fv <- merge(kwic_refu, 
                     doc_id_date, 
                     by = "docname", 
                     all.x = TRUE, 
                     sort = FALSE)
kwic_asyl_fv <- merge(kwic_asyl, 
                     doc_id_date, 
                     by = "docname", 
                     all.x = TRUE, 
                     sort = FALSE)

```

*Graph 3: KWIC sentiment*
#### I think this should also be discarded. It is kind of strange maybe to plot sentiment based on bubbles of 40 words at a time, or, we could justify it by assuming that in these bubbles speeches are likely to be really related to immigration which is also where most sentiment is likely to be voiced. But I am not that convinced by this myself.  

```{r kwic sentiment by party immigra, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE}

kwic_imm_fv$date <- as.Date(kwic_imm_fv$date, format="%Y-%m-%d")

kwic_imm_party <- kwic_imm_fv %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

ggplot(kwic_imm_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in context of immigra* by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

```

```{r kwic sentiment by party refuge, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE}

kwic_refu_fv$date <- as.Date(kwic_refu_fv$date, format="%Y-%m-%d")

kwic_refu_party <- kwic_refu_fv %>% 
  group_by(month=floor_date(date, "month"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

ggplot(kwic_refu_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in context of refuge* by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

```

```{r kwic sentiment by party asylum, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE}

kwic_asyl_fv$date <- as.Date(kwic_asyl_fv$date, format="%Y-%m-%d")

kwic_asyl_party <- kwic_asyl_fv %>% 
  group_by(month=floor_date(date, "year"), party = party) %>% 
  summarise(avg_sentiment = mean(sentiment))

ggplot(kwic_asyl_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  geom_line(data = subset(HoC_senti_data_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  labs(title = "Observed Sentiment in context of asylum by party",
       subtitle = "Conservative = blue, Labour = red",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.numeric(as.Date(events$vals)),
             colour = c("black","red"),
             show.legend = FALSE, linetype ="dashed")+
  theme(axis.text.x = element_text(angle = 90))

```

```{r sentiment kwic graph 3, results = 'hide', message = FALSE, warning=FALSE, echo=FALSE}

kwic_senti <- data.frame(kwic_imm_fv %>% 
  group_by(month=floor_date(date, "year")) %>% 
  summarise(avg_sentiment = mean(sentiment)),
kwic_refu_party <- kwic_refu_fv %>% 
  group_by(month=floor_date(date, "year")) %>% 
  summarise(avg_sentiment = mean(sentiment)),
kwic_refu_party <- kwic_asyl_fv %>% 
  group_by(month=floor_date(date, "year")) %>% 
  summarise(avg_sentiment = mean(sentiment)))

kwic_senti <- data.frame(date = kwic_senti$month, immigra = kwic_senti$avg_sentiment, refuge = kwic_senti$avg_sentiment.1 ,asylum = kwic_senti$avg_sentiment.2)

kwic_senti$date <- as.Date(kwic_senti$date, format="%Y-%m-%d")

ggplot(kwic_senti, aes(x=date)) +
  geom_line(color="red",aes(y=immigra)) +
  geom_line(color="green",aes(y=refuge)) +
  geom_line(color="black",aes(y=asylum)) +
  labs(title = "Observed Sentiment in Context of Keywords",
       subtitle = "red = immigra*, green = refuge*, black = asylum",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum") +
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red") + # Brexit referendum
  theme(axis.text.x = element_text(angle = 90))

```


## 6. Topics

*Create Dfm* Include here to also include sentiment in the dfm.
```{r topics_dfm, message = FALSE, warning=FALSE}

HoC_dfm <- dfm(HoC_corp, 
                  remove_punct = TRUE,
                  remove = stopwords(),
                  remove_symbols = TRUE,
                  remove_separators = TRUE,
                  split_hyphens = TRUE,
                  remove_numbers = TRUE)

HoC_dfm <- dfm_trim(HoC_dfm,
                  min_termfreq = 2, 
                  min_docfreq = 2)
HoC_dfm <- dfm_subset(HoC_dfm, rowSums(HoC_dfm)>0)

HoC_stm <-asSTMCorpus(HoC_dfm)
```

```{r topics, message=FALSE, warning=FALSE}
########################
# Running topic model 1#
########################
# fit a simple model with 6 topics
topic_mod_1 <- stm(HoC_dfm, K = 6, seed = 12345)
topic_labels <- labelTopics(topic_mod_1)
plot(topic_mod_1, type = "labels", labeltype = "prob") # or frex, lift, score

# extract paragraphs most aligned with each topic
# thoughts <- findThoughts(topic_mod_1, texts = texts(HoC_corp), n=1, topics = c(1:6))#n=how many documents
#plot thoughts for topics ---> Ofer needs help with this one!
# stm::plotQuote(thoughts$docs, width = 80, text.cex=0.6)
# save(thoughts, file = "thoughts.RData")

# wordcloud textplot_wordcloud
# cloud(topic_mod_1, topic = 6, max_words = 90, color = c(color =rev(RColorBrewer::brewer.pal(10, "RdBu"))))

# check if topics are exclusive
dotchart(exclusivity(topic_mod_1), labels = 1:6, color = 1:6)

# check if topics are coherent
cohere <- semanticCoherence(topic_mod_1, HoC_dfm)
cohere
dotchart(cohere, labels = 1:6, color = 1:6)

#topic model key words in context
#topic_mod_2 <- stm(HoC_kwic_dfm, K = 6, seed = 12345)
#topic_labels_2 <- labelTopics(topic_mod_2)
#plot(topic_mod_2, type = "labels", labeltype = "prob") 
# extract paragraphs most aligned with each topic
#thoughts_2 <- findThoughts(topic_mod_2, texts = texts(HoC_kwic_corp), n=1, topics = c(1:6)) #n=how many documents
#save(thoughts_2, file = "thoughts_2.RData")
#plot thoughts for topics
#stm::plotQuote(thoughts_2$docs, width = 80, text.cex=0.6)
```

The topics found by the stm model are exclusive 

```{r topics dataframe, message = FALSE, warning=FALSE}
###################################
# Creating topic model data frame #
###################################

# combine stm thetas with dfm docvars
HoC_theta_data <- as.data.frame(topic_mod_1$theta) %>%
  cbind(docvars(HoC_dfm))

## naming topics
#combine first 3 labels as a string for a new label
labels_topic_mod_1 <- c()
for (topicnumber in topic_labels$topicnums){
  first_3<-(str_c(topic_labels$frex[topicnumber,1], 
                  ", " , topic_labels$frex[topicnumber,2], 
                  ", " , topic_labels$frex[topicnumber,3]))
  labels_topic_mod_1<- append(labels_topic_mod_1, first_3)
}

# renaming columns
names(HoC_theta_data)[1:6] <- labels_topic_mod_1


###

####################################
# save/load topic model data frame #
####################################

# save and load topic model dataframe
save(HoC_theta_data, file = "HoC_theta_data.RData")
load("HoC_theta_data.RData")
```


*Topic Visualizations:*

```{r topic_by_party_plot, message = FALSE, warning=FALSE}

## topic_by_party_plot: topic proportions by party 

# grouping by party and generating means 
theta_data_party <- HoC_theta_data %>%
  group_by(party)

theta_data_party_mean <- aggregate(theta_data_party[, 1:6], 
                                   list(theta_data_party$party), 
                                   mean)
names(theta_data_party_mean)[1] <- "Party" 

# Turning into a table of proportions
theta_data_party_prop <- theta_data_party_mean[1] %>%
  cbind(as.data.frame(
    round(100*prop.table(theta_data_party_mean[2:7]),
          digits=2)))

# pivoting df for making figure
party_prop_long <-theta_data_party_prop %>%
  pivot_longer(c(2:7), 
               names_to = "Topic", 
               values_to = "Proportion")

# visualizing proportions of topics by party
topic_by_party_plot <- party_prop_long %>%
  ggplot(aes(Party, Proportion, fill = Topic)) +
  geom_bar(position = "fill", stat = "identity") +
  scale_y_continuous() + 
  theme(axis.text.x = element_text(angle = 45, 
                                   hjust = 1, 
                                   size = 6))
topic_by_party_plot
```


```{r topics_by_time_plot, message = FALSE, warning=FALSE}

## topic_by_party_plot: topic proportions by party 

theta_data_long <- pivot_longer(
  HoC_theta_data, 
  cols = names(HoC_theta_data[1:6]), 
  names_to = "topic",
  values_to = "theta")

# plot topic theta means over years
theta_long_data_year <- theta_data_long %>%
  mutate(year = str_sub(date, 1, 4)) %>%
  group_by(year, topic) %>% 
  dplyr::summarise(theta.means = mean(theta))


ggplot(theta_long_data_year,aes(x=year, y=theta.means, group = 1, color = topic)) + 
  geom_point() +
  geom_line() +
  geom_vline(xintercept = "2015", linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = "2016", linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~topic)
```

```{r ind_topics_by_time_by_party_plot, message = FALSE, warning=FALSE}

####### showing development of 1 topic over time across parties
# plot topic theta means by party over years
theta_long_data_year_1 <- theta_data_long %>%
  mutate(year = str_sub(date, 1, 4)) %>%
  group_by(year, topic, party) %>% 
  dplyr::summarise(theta.means = mean(theta))

# plot all parties together (plot by topic, color by party)
k <- ggplot()  +
  geom_line(data = theta_long_data_year_1, aes(x=year, y = theta.means, group = party, colour = party)) + 
  geom_line(data = theta_long_data_year,aes(x=year, y=theta.means, group = 1)) +
  geom_vline(xintercept = "2015", linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = "2016", linetype = "dashed", color = "red")+ # Brexit referendum
  facet_wrap(~topic)

# make interactive
k <- ggplotly(k)

k
```

*sentiment and Topics: Correlation*
```{r topics-sentiment correlation,message = FALSE, warning=FALSE}

##### cor()
cor_sent_top_1 <- cor(theta_data_party[1],theta_data_party$sentiment)
cor_sent_top_2 <- cor(theta_data_party[2],theta_data_party$sentiment)
cor_sent_top_3 <- cor(theta_data_party[3],theta_data_party$sentiment)
cor_sent_top_4 <- cor(theta_data_party[4],theta_data_party$sentiment)
cor_sent_top_5 <- cor(theta_data_party[5],theta_data_party$sentiment)
cor_sent_top_6 <- cor(theta_data_party[6],theta_data_party$sentiment)
cor_sent_top <- rbind(cor_sent_top_1,cor_sent_top_2,cor_sent_top_3,cor_sent_top_4,cor_sent_top_5,cor_sent_top_6)
colnames(cor_sent_top) = "correlation"
cor_top

#library(stargazer)
#stargazer(reg1, reg2, reg3, reg4, reg5, reg6)

```

```{r topics-sentiment regression plot, echo=FALSE}
# for all parties (no color)
ggplot(theta_data_long_reg,aes(y=sentiment,x=theta)) +
  #geom_point(alpha = 0.05, shape = ".") +
  geom_smooth(method="lm", show.legend = FALSE) +
  theme_bw() + 
  xlab("Topic Theta") +
  ylab("Sentiment") +
  ggtitle("Correlation Between Sentiment and Topic") +
  facet_wrap(~topic)
```

```{r topics-sentiment regression plot by party, echo=FALSE}
# for all parties (color)
ggplot(theta_data_long_reg,aes(y=sentiment,x=theta, color = party, fill = party)) +
  #geom_point(alpha = 0.05, shape = ".") +
  geom_smooth(method="lm") +
  theme_bw() + 
  xlab("Topic Theta") +
  ylab("Sentiment") +
  ggtitle("Correlation Between Sentiment and Topic") +
  facet_wrap(~topic)
```









## 7. Exploratory part (just for ourselves)
Leave out in the end!

*Descriptive*
```{r topics_5, eval=FALSE, include=FALSE}
# fit a simple model with 12 topics
topic_mod_2 <- stm(HoC_dfm, K = 12, seed = 12345)
labelTopics(topic_mod_2)
#plot(topic_mod_2, type = "labels", labeltype = "prob") # or frex, lift, score
findThoughts
# check if topics are exclusive 
dotchart(exclusivity(topic_mod_2), labels = 1:12)

#check if topics are coherent
cohere <- semanticCoherence(topic_mod_2, HoC_dfm)
dotchart(cohere, labels = 1:12)

```


```{r topics_6, eval=FALSE, include=FALSE}
# topic model prevelance by party
# new topic model mod3  --> @Amir check why error showss up regarding content covariate lenght? 

topic_mod_3 <- stm(HoC_stm$documents, vocab = HoC_stm$vocab, 
             K = 6, ~ party, data=HoC_stm$data, seed = 12345)
#estimating the effect in term of topic-proportions which are the outcome variable. 
#conditional expectation of topic prevalence given document characteristics.
topic_mod_3 <- estimateEffect(1:6~HoC_stm$party, topic_mod_1, HoC_stm)

#plot to see exclusivity of topics
plot(topicCorr(topic_mod_3))
#plot to chec
topicQuality(topic_mod_3, documents = HoC_stm$documents)
dim(topic_mod_3$beta$logbeta[[1]])

#code to add labels
labels <- apply(sageLabels(topic_mod_1)$marginal$frex, 1,
                function(x){ paste(x[1:4], collapse = "-") })


```

*Just to check what the sentiment analysis does*
```{r just for us, eval=FALSE, include=FALSE}

text <- data.frame(text =c("nice","evil","and"))
text <- corpus(text)
sent_text <- textstat_polarity(text, 
                               data_dictionary_LSD2015)
```

```{r just for us_2, eval=FALSE, include=FALSE}

#### Sentiment only for refugee* by party
refu <- c("refugee*","Refugee*")
refugee <- filter(HoC_corp_time, grepl(paste(refu,collapse="|"), agenda) | grepl(paste(refu,collapse="|"), text))
refcorp <- corpus(refugee)

ref_sent <- textstat_polarity(refcorp, 
                              data_dictionary_LSD2015)
ref_sent$sent_prob <- 1/(1 + exp(-ref_sent$sentiment))

refugee = cbind(refugee,ref_sent)

refugee$date <- as.Date(refugee$date, format="%Y-%m-%d")
ref_party_df <- data.frame(date = refugee$date, party = refugee$party ,sentiment = refugee$sentiment)
ref_party = ref_party_df %>% group_by(month=floor_date(date, "month"), party = party) %>% summarise(avg_sentiment = mean(sentiment))

ggplot(ref_party)+
  geom_line(aes(x=month, y=avg_sentiment,group = party), colour = "grey",size = 1) +
  geom_line(data = subset(ref_party, party == "Con") ,aes(x=month, y=avg_sentiment,group = party), colour = "red",size = 1) +
  geom_line(data = subset(ref_party, party == "Lab") ,aes(x=month, y=avg_sentiment,group = party), colour = "blue",size = 1) +
  labs(title = "Observed Sentiment in refugee*- related contributions overall by party",
       subtitle = "Conservative = red, Labour = blue",
       caption = "dashed line (black = 2015 general election, red = Brexit referendum")+
  geom_vline(xintercept = as.Date("2015-05-07"), linetype = "dashed")+ #general election 2015
  geom_vline(xintercept = as.Date("2016-06-23"), linetype = "dashed", color = "red")+ # Brexit referendum
  theme(axis.text.x = element_text(angle = 90))


```


## Keywords in Context - Wordclouds
Justification and Thoughts here.
To understand better how key words are discussed in the text we first generated a key words in context data frame which constraints the corpus to only words that appear 20 words before a key word and 20 words after. 

*KWIC - Wordcloud incl. keywords*
```{r kwic, eval=FALSE, include=FALSE}
textplot_wordcloud(HoC_kwic_dfm, max_words = 90, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
```

*KWIC - Wordcloud excl. keywords*
```{r kwic_2, eval=FALSE, include=FALSE}

## removing also key words to see what is left
HoC_kwic_dfm_no_key <- dfm(HoC_kwic_corp,
                       remove_punct = TRUE,
                       remove = c(as.vector(key_words_img),stopwords()),
                       remove_symbols = TRUE,
                       remove_separators = TRUE,
                       split_hyphens = TRUE,
                       remove_numbers = TRUE)

textplot_wordcloud(HoC_kwic_dfm_no_key, max_words = 90, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
```

*Plot: Top words co-concurence matrix of key words in context*
```{r kwic_3, eval=FALSE, include=FALSE}
#plot feature concourence matrix
HoC_kwic_fcm <-
  tokens(HoC_kwic_corp, remove_punct = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("english"), padding = FALSE) %>%
  fcm(context = "window", window = 5, tri = FALSE)
# choose 30 most frequency features
topfeats <- names(topfeatures(HoC_kwic_fcm, 30))
# select the top 30 features only, plot the network
set.seed(100)
textplot_network(fcm_select(HoC_kwic_fcm, topfeats), min_freq = 0.8)
```

*Frequency of words related to migration (including key terms)*
```{r kwic_4, eval=FALSE, include=FALSE}

HoC_dfm_word_freq <- textstat_frequency(HoC_dfm, n=100)
# Sort by reverse frequency order
HoC_dfm_word_freq$feature <- with(HoC_dfm_word_freq, reorder(feature, -frequency))

ggplot(HoC_dfm_word_freq, 
       aes(x = feature, y = frequency)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
